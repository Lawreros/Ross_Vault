### Achievements


### TODO
- Catch up on Matrix Lectures
- 2-3 hours of overleaf
- Dump everything into Anki and push to github

### Train of thought:
- Watched Matrix analysis lectures (September 10th and 13th)
- 
- Lab Lunch meeting (Tyler Tomita)
		- Continual Learning (Using training on a previous similar task in order to increase performance/learning rate on a new task)
		- *Task Unaware Continual Learning and Transfer via Contextual Representation Ensembling*
		- "Machine Continual Learning"
		- "Catastrophic forgetting"
		- "Task-aware" setting (where the learner is explicitly told the task)
		- "Contextual Representation Ensembling"
				- have multiple different "experts" trained on different aspects of the task, then have an ensambler take their outputs and process them into one output (think Random Forest, but with a more nuanced "vote" count)
		- "CFAR task" (ml training set)
		- "MNIST task" (ml training set)
		- 

